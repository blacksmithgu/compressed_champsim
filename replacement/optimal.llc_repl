#include "cache.h"
#include "champsim.h"
#include "instruction.h"

// The cache model/generator to use; OPTgen by default.
#ifndef CACHEGEN
    #define CACHEGEN OPTgen<1024>
#endif

#ifndef BATCH_CACHEGEN
    #define BATCH_CACHEGEN DelegatingGen<CACHEGEN>
#endif

using namespace std;

/**
 * A batched cache decision generator; may potentially generate multiple decisions or no decisions at all in each call.
 */
class BatchCachegen {
    virtual ~BatchCachegen() {}

    // Try to cache the usage interval from (start_time, end_time) inclusive, with the given compression factor and full
    // address.
    virtual std::vector<std::pair<uint64_t, bool>> try_cache(uint64_t start_time, uint64_t end_time, uint64_t full_addr, uint32_t cf) = 0;
};

/**
 * A structure containing all of the relevant information about a cache access.
 */
struct CacheAccess {
    // The cpu the access originated from.
    uint32_t cpu;

    // The specific set which this access went to.
    uint32_t set;

    // The specific memory address which was accessed.
    uint32_t full_address;

    // The address of the start of the cache line the memory address is a part of.
    uint32_t line_address;

    // The Optgen-specific time quanta that this access occurred at, measured in accesses to that Optgen structure.
    uint32_t optgen_time;

    // The PC which generated this access.
    uint32_t pc;

    // The compression factor of the cache line upon insertion.
    uint32_t compression_factor;

    // The prediction made for this cache access (false for miss, true for hit).
    bool prediction;

    CacheAccess(uint32_t cpu, uint32_t set, uint32_t full_address, uint32_t line_address,
            uint32_t optgen_time, uint32_t pc, uint32_t cf, bool prediction)
        : cpu(cpu), set(set), full_address(full_address), line_address(line_address),
        optgen_time(optgen_time), pc(pc), compression_factor(cf), prediction(prediction) {}

    CacheAccess() {}
};

// A map of address -> full cache accesses which we use in order to compute the optimal solution.
map<uint64_t, CacheAccess> outstanding_accesses;

// A per-set collection of cachegen data structures, used to compute the optimal labels of specific cache accesses.
CACHEGEN optgens[LLC_SET];

// A local "timer" counting the number of accesses to each set/optgen.
uint32_t num_accesses[LLC_SET] = {0};

// The total number of hits & misses.
uint32_t hits = 0, misses = 0;

uint32_t CACHE::llc_find_victim_cc(uint32_t cpu, uint64_t instr_id, uint32_t set, const COMPRESSED_CACHE_BLOCK *current_set,
        uint64_t ip, uint64_t full_addr, uint32_t type, uint64_t incoming_cf, uint32_t& evicted_compressed_index) {
    // 1st Variant: Look for empty/invalid space in a superblock line.
    for(uint32_t way = 0; way < LLC_WAY; way++) {
        // Ignore lines w/ a different superblock.
        if(current_set[way].sbTag != get_sb_tag(line_addr)) continue;

        // Ignore lines of a different compression factor.
        if(current_set[way].compressionFactor != incoming_cf) continue;

        for(uint32_t compression_index = 0; compression_index < current_set[way].compressionFactor; compression_index++) {
            // Ignore valid lines.
            if(current_set[way].valid[compression_index]) continue;

            // We've found an invalid line, return it.
            evicted_compressed_index = compression_index;
            return way;
        }
    }

    // 2nd Variant: Look for a plain invalid way.
    for(uint32_t way = 0; way < LLC_WAY; way++) {
        // Valid ways have CF > 0.
        if(current_set[way].compressionFactor != 0) continue;

        // Otherwise, we found a line.
        evicted_compressed_index = 0;
        return way;
    }

    //Step 3: Evict a superblock using LRU.
    uint32_t max_lru = 0;
    uint32_t victim = 0;
    for (uint32_t way = 0; way < NUM_WAY; way++) {
        if (current_set[way].lru > max_lru) {
            max_lru = current_set[way].lru;
            victim = way;
        }
    }

    evicted_cf_index = 4;
    return victim;
}

void CACHE::llc_update_replacement_state_cc(uint32_t cpu, uint32_t set, uint32_t way, uint32_t compressed_index, uint64_t full_addr, uint64_t ip,
        uint64_t victim_addr, uint32_t type, uint32_t cf, uint8_t hit, uint64_t latency, uint64_t effective_latency) {
    // Writeback hit does not update LRU state
    if (type == WRITEBACK && hit) return;

    // Age all other lines.
    for (uint32_t i=0; i<NUM_WAY; i++) {
        // Skip invalid lines.
        if(compressed_cache_block[set][i].compressionFactor == 0) continue;

        // Age all lines younger than the accessed line.
        if (compressed_cache_block[set][i].lru < compressed_cache_block[set][way].lru)
            compressed_cache_block[set][i].lru++;
    }

    compressed_cache_block[set][way].lru = 0; // promote to the MRU position

    // Handle optimal computations (we're stealing the LLC stream from ChampSim, essentially).

    uint64_t line_addr = full_addr & ~(BLOCK_SIZE - 1);

    // If we've seen an access to this cache line before, then update the opt. generator and output this cache access.
    auto access_iter = outstanding_accesses.find(line_addr);
    if(access_iter != outstanding_accesses.end()) {
        CacheAccess& access = access_iter->second;

        // Try to cache and get a list of batched decisions.
        auto decisions = optgens[set].try_cache(access.optgen_time, num_accesses[set], access.full_address, access.compression_factor);

        for(auto decision : decisions) {
            if(decision.second) hits++;
            else misses++;
        }
    }

    // Add the current access to the list of cache accesses, passing it to the predictor.
    CacheAccess access = CacheAccess(cpu, set, full_addr, line_addr, num_accesses[set], ip, cf, true);
    outstanding_accesses[line_addr] = access;
    num_accesses[set]++;
}

void CACHE::llc_replacement_final_stats() {
    std::cout << std::endl << std::endl;
    std::cout << "Total Accesses: " << (hits + misses) << std::endl;
    std::cout << "Hits: " << hits << std::endl;
    std::cout << "Misses: " << misses << std::endl;
}
