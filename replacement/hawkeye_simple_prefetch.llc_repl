//Hawkeye Cache Replacement Tool v2.0
//UT AUSTIN RESEARCH LICENSE (SOURCE CODE)
//The University of Texas at Austin has developed certain software and documentation that it desires to
//make available without charge to anyone for academic, research, experimental or personal use.
//This license is designed to guarantee freedom to use the software for these purposes. If you wish to
//distribute or make other use of the software, you may purchase a license to do so from the University of
//Texas.
///////////////////////////////////////////////
//                                            //
//     Hawkeye [Jain and Lin, ISCA' 16]       //
//     Akanksha Jain, akanksha@cs.utexas.edu  //
//                                            //
///////////////////////////////////////////////

// Source code for configs 1 and 2

#include "cache.h"
#include "uncore.h"
#include <map>
#include <cassert>
#include "hawkeyegen.h"

#define LLC_SETS LLC_SET
#define LLC_WAYS LLC_WAY

//3-bit RRIP counters or all lines
#define maxRRPV 7
uint32_t rrpv[LLC_SETS][LLC_WAYS];
uint64_t perset_mytimer[LLC_SETS];

// Signatures for sampled sets; we only use 64 of these
// Budget = 64 sets * 16 ways * 12-bit signature per line = 1.5B
uint64_t signatures[LLC_SETS][LLC_WAYS];
bool prefetched[LLC_SETS][LLC_WAYS];

// Hawkeye Predictors for demand and prefetch requests
// Predictor with 2K entries and 5-bit counter per entry
// Budget = 2048*5/8 bytes = 1.2KB
#define MAX_SHCT 31
#define SHCT_SIZE_BITS 14
//#define SHCT_SIZE_BITS 11
#define SHCT_SIZE (1<<SHCT_SIZE_BITS)
#include "hawkeye_predictor.h"
HAWKEYE_PC_PREDICTOR* demand_predictor;  //Predictor
HAWKEYE_PC_PREDICTOR* prefetch_predictor;  //Predictor

#include "optgen_simple.h"
OPTgen perset_optgen[LLC_SETS]; // per-set occupancy vectors; we only use 64 of these
HAWKEYEgen perset_hawkeyegen[LLC_SETS]; // per-set occupancy vectors; we only use 64 of these

#include <math.h>
#define bitmask(l) (((l) == 64) ? (unsigned long long)(-1LL) : ((1LL << (l))-1LL))
#define bits(x, i, l) (((x) >> (i)) & bitmask(l))
//Sample 64 sets per core
//#define SAMPLED_SET(set) (bits(set, 0 , 6) == bits(set, ((unsigned long long)log2(LLC_SETS) - 6), 6) )
#define SAMPLED_SET(set) (bits(set, 0 , 8) == bits(set, ((unsigned long long)log2(LLC_SETS) - 8), 8) )

// Sampler to track 8x cache history for sampled sets
// 2800 entris * 4 bytes per entry = 11.2KB
#define SAMPLED_CACHE_SIZE 2800*NUM_CPUS
map<uint64_t, ADDR_INFO> addr_history; // Sampler
map<uint64_t, LRUADDR_INFO> hawkeyegen_addr_history; // Sampler

// initialize replacement state
void CACHE::llc_initialize_replacement()
{
    for (int i=0; i<LLC_SETS; i++) {
        for (int j=0; j<LLC_WAYS; j++) {
            rrpv[i][j] = maxRRPV;
            signatures[i][j] = 0;
            prefetched[i][j] = false;
        }
        perset_mytimer[i] = 0;
        perset_optgen[i].init(LLC_WAYS-2);
        perset_hawkeyegen[i].init(LLC_WAYS);
    }

    addr_history.clear();

    demand_predictor = new HAWKEYE_PC_PREDICTOR();
    prefetch_predictor = new HAWKEYE_PC_PREDICTOR();
    cout << "Initialize Hawkeye state" << endl;
}

// find replacement victim
// return value should be 0 ~ 15 or 16 (bypass)
uint32_t CACHE::llc_find_victim(uint32_t cpu, uint64_t instr_id, uint32_t set, const BLOCK *current_set, uint64_t ip, uint64_t full_addr, uint32_t type)
{
    // look for the maxRRPV line
    for (uint32_t i=0; i<LLC_WAYS; i++)
        if (rrpv[set][i] == maxRRPV)
            return i;

    //If we cannot find a cache-averse line, we evict the oldest cache-friendly line
    uint32_t max_rrip = 0;
    int32_t lru_victim = -1;
    for (uint32_t i=0; i<LLC_WAYS; i++)
    {
        if (rrpv[set][i] >= max_rrip)
        {
            max_rrip = rrpv[set][i];
            lru_victim = i;
        }
    }

    assert (lru_victim != -1);
    //The predictor is trained negatively on LRU evictions
    if( SAMPLED_SET(set) )
    {
        if(prefetched[set][lru_victim])
            prefetch_predictor->decrement(signatures[set][lru_victim]);
        else
            demand_predictor->decrement(signatures[set][lru_victim]);
    }
    return lru_victim;

    // WE SHOULD NOT REACH HERE
    assert(0);
    return 0;
}

void replace_addr_history_element()
{
    uint64_t lru_addr = 0;
    uint64_t lru_time = 10000000;

    for(map<uint64_t, ADDR_INFO>::iterator it=addr_history.begin(); it != addr_history.end(); it++)
    {
        if((it->second).last_quanta < lru_time)
        {
            lru_time =  (it->second).last_quanta;
            lru_addr = it->first;
        }
    }
    assert(lru_addr != 0);
    addr_history.erase(lru_addr);
}

uint64_t timer = 0;

void simulate_hawkeye_gen(uint32_t set, uint64_t paddr, bool prediction, bool prefetch)
{
    timer++;
    uint64_t curr_quanta = perset_mytimer[set];

    if(hawkeyegen_addr_history.find(paddr) != hawkeyegen_addr_history.end())
    {
        uint64_t last_quanta = hawkeyegen_addr_history[paddr].last_quanta;
        if(hawkeyegen_addr_history[paddr].prefetched)   
        {
            assert(hawkeyegen_addr_history[paddr].last_prefetch_quanta != 0);
            last_quanta = hawkeyegen_addr_history[paddr].last_prefetch_quanta;
        }

        bool last_prediction = hawkeyegen_addr_history[paddr].prediction;

        perset_hawkeyegen[set].should_cache(last_prediction, curr_quanta, last_quanta, prefetch);
        if(last_prediction)
            perset_hawkeyegen[set].add_access(prediction, curr_quanta, last_quanta, prefetch);
        else
            perset_hawkeyegen[set].add_access(prediction, curr_quanta, prefetch);
    }
    else
    {
        hawkeyegen_addr_history[paddr].init(curr_quanta);
        perset_hawkeyegen[set].add_access(prediction, curr_quanta, prefetch);
    }
}




uint64_t average_latency[NUM_CPUS] = {0};
uint64_t average_latency_count[NUM_CPUS] = {0};

// called on every cache hit and cache fill
void CACHE::llc_update_replacement_state(uint32_t cpu, uint32_t set, uint32_t way, uint64_t full_addr, uint64_t ip, uint64_t victim_addr, uint32_t type, uint8_t hit, uint64_t latency, uint64_t effective_latency)
{
    uint64_t paddr = (full_addr >> 6) << 6;

    if(type == PREFETCH)
    {
        if (!hit)
            prefetched[set][way] = true;
    }
    else
        prefetched[set][way] = false;

    //Ignore writebacks
    if (type == WRITEBACK)
        return;

    if(!hit) {
        average_latency[cpu] += latency;
        average_latency_count[cpu] += 1;
    }

    //If we are sampling, OPTgen will only see accesses from sampled sets
    if(SAMPLED_SET(set))
    {
        //The current timestep 
        uint64_t curr_quanta = perset_mytimer[set];

        // This line has been used before. Since the right end of a usage interval is always 
        //a demand, ignore prefetches
        if((addr_history.find(paddr) != addr_history.end()) && (type != PREFETCH))
        {
            uint64_t last_quanta = addr_history[paddr].last_quanta;
            assert(curr_quanta >= addr_history[paddr].last_quanta);

            if( perset_optgen[set].should_cache(curr_quanta, last_quanta))
            {
                if(addr_history[paddr].prefetched)
                    prefetch_predictor->increment(addr_history[paddr].PC);
                else 
                    demand_predictor->increment(addr_history[paddr].PC);
            }
            else
            {
                //Train the predictor negatively because OPT would not have cached this line
                if(addr_history[paddr].prefetched) 
                    prefetch_predictor->decrement(addr_history[paddr].PC);
                else 
                    demand_predictor->decrement(addr_history[paddr].PC);
            }
            //Some maintenance operations for OPTgen
            perset_optgen[set].add_access(curr_quanta);

            //Since this was a demand access, mark the prefetched bit as false
            addr_history[paddr].prefetched = false;
        }
        // This is the first time we are seeing this line (could be demand or prefetch)
        else if(addr_history.find(paddr) == addr_history.end())
        {
            // Find a victim from the sampled cache if we are sampling
            assert(addr_history.size() <= SAMPLED_CACHE_SIZE);
            if(addr_history.size() == SAMPLED_CACHE_SIZE) 
                replace_addr_history_element();

            assert(addr_history.size() < SAMPLED_CACHE_SIZE);
            //Initialize a new entry in the sampler
            addr_history[paddr].init(curr_quanta);
            //If it's a prefetch, mark the prefetched bit;
            if(type == PREFETCH)
                perset_optgen[set].add_prefetch(curr_quanta);
            else
                perset_optgen[set].add_access(curr_quanta);
        }
        else //This line is a prefetch
        {
            assert(addr_history.find(paddr) != addr_history.end());
            uint64_t last_quanta = addr_history[paddr].last_quanta;

            if (perset_mytimer[set] - addr_history[paddr].last_quanta < 5*NUM_CPUS) 
            {
                if(perset_optgen[set].should_cache(curr_quanta, last_quanta, true))
                {
                    if(addr_history[paddr].prefetched) // P-P
                        prefetch_predictor->increment(addr_history[paddr].PC);
                    else //D-P
                        demand_predictor->increment(addr_history[paddr].PC);
                }
            }

            perset_optgen[set].add_prefetch(curr_quanta);
        }

        // Get Hawkeye's prediction for this line
        bool new_prediction = demand_predictor->get_prediction (ip);
        if (type == PREFETCH)
            new_prediction = prefetch_predictor->get_prediction (ip);

        // Update the sampler with the timestamp, PC and our prediction
        // For prefetches, the PC will represent the trigger PC
        addr_history[paddr].update(perset_mytimer[set], ip, new_prediction);
        if(type == PREFETCH)
            addr_history[paddr].mark_prefetch(); 
        else
            addr_history[paddr].prefetched = false; 
        addr_history[paddr].lru = 0;
        //Increment the set timer
    }

    perset_mytimer[set] = (perset_mytimer[set]+1);
    bool new_prediction = demand_predictor->get_prediction (ip);
    if (type == PREFETCH)
        new_prediction = prefetch_predictor->get_prediction (ip);

    signatures[set][way] = ip;


    simulate_hawkeye_gen(set, paddr, new_prediction, (type == PREFETCH));
    uint64_t curr_quanta = perset_mytimer[set];
    if(type == PREFETCH)
        hawkeyegen_addr_history[paddr].update_prefetch(curr_quanta, ip, new_prediction);
    else
        hawkeyegen_addr_history[paddr].update(curr_quanta, ip, new_prediction);



    //Set RRIP values and age cache-friendly line
    if(!new_prediction)
        rrpv[set][way] = maxRRPV;
    else
    {
        rrpv[set][way] = 0;
        if(!hit)
        {
            bool saturated = false;
            for(uint32_t i=0; i<LLC_WAYS; i++)
                if (rrpv[set][i] == maxRRPV-1)
                    saturated = true;

            //Age all the cache-friendly  lines
            for(uint32_t i=0; i<LLC_WAYS; i++)
            {
                if (!saturated && rrpv[set][i] < maxRRPV-1)
                    rrpv[set][i]++;
            }
        }
        rrpv[set][way] = 0;
    }
}

// use this function to print out your own stats at the end of simulation
void CACHE::llc_replacement_final_stats()
{
    unsigned int hits = 0;
    unsigned int accesses = 0;
    unsigned int traffic = 0;
    unsigned int hawkeyegen_hits = 0;
    unsigned int hawkeyegen_rp = 0;
    unsigned int hawkeyegen_accesses = 0;
    unsigned int hawkeyegen_prefetches = 0;


    for(unsigned int i=0; i<LLC_SETS; i++)
    {
        accesses += perset_optgen[i].access;
        hits += perset_optgen[i].get_num_opt_hits();
        traffic += perset_optgen[i].get_traffic();

        hawkeyegen_hits += perset_hawkeyegen[i].hit;
        hawkeyegen_rp += perset_hawkeyegen[i].redundant_prefetch;
        hawkeyegen_accesses += perset_hawkeyegen[i].access;
        hawkeyegen_prefetches += perset_hawkeyegen[i].prefetch_access;
    }

    std::cout << "OPTgen accesses: " << accesses << std::endl;
    std::cout << "OPTgen hits: " << hits << std::endl;
    std::cout << "OPTgen hit rate: " << 100*(double)hits/(double)accesses << std::endl;
    std::cout << "Traffic: " << traffic << " " << 100*(double)traffic/(double)accesses << std::endl;

    cout << endl << endl;
    cout << "Hawkeyegen stats: " << hawkeyegen_hits << " " << hawkeyegen_accesses << " " << 100*(double)hawkeyegen_hits/(double)hawkeyegen_accesses << endl;
    cout << "Hawkeyegen prefetches: " << hawkeyegen_rp << " " << hawkeyegen_prefetches << " " << 100*(double)hawkeyegen_rp/(double)hawkeyegen_prefetches << endl;
 
    cout << endl << endl;
    cout << "Average latency Core 0: " << (double)average_latency[0]/(double)average_latency_count[0] << endl;
    cout << "Average latency Core 1: " << (double)average_latency[1]/(double)average_latency_count[1] << endl;
    cout << "Average latency Core 2: " << (double)average_latency[2]/(double)average_latency_count[2] << endl;
    cout << "Average latency Core 3: " << (double)average_latency[3]/(double)average_latency_count[3] << endl;
    return;
}
