//Hawkeye Cache Replacement Tool v2.0
//UT AUSTIN RESEARCH LICENSE (SOURCE CODE)
//The University of Texas at Austin has developed certain software and documentation that it desires to
//make available without charge to anyone for academic, research, experimental or personal use.
//This license is designed to guarantee freedom to use the software for these purposes. If you wish to
//distribute or make other use of the software, you may purchase a license to do so from the University of
//Texas.
///////////////////////////////////////////////
//                                            //
//     Hawkeye [Jain and Lin, ISCA' 16]       //
//     Akanksha Jain, akanksha@cs.utexas.edu  //
//                                            //
///////////////////////////////////////////////

// Source code for configs 1 and 2

#include "cache.h"
#include "uncore.h"
#include <map>
#include <cassert>

#define LLC_SETS LLC_SET
#define LLC_WAYS LLC_WAY

//3-bit RRIP counters or all lines
#define maxRRPV 7
uint32_t rrpv[LLC_SETS][LLC_WAYS];
uint64_t perset_mytimer[LLC_SETS];

// Signatures for sampled sets; we only use 64 of these
// Budget = 64 sets * 16 ways * 12-bit signature per line = 1.5B
uint64_t signatures[LLC_SETS][LLC_WAYS];
uint64_t addresses[LLC_SETS][LLC_WAYS];
bool prefetched[LLC_SETS][LLC_WAYS];

// Hawkeye Predictors for demand and prefetch requests
// Predictor with 2K entries and 5-bit counter per entry
// Budget = 2048*5/8 bytes = 1.2KB
#define MAX_SHCT 31
//#define SHCT_SIZE_BITS 14
#define SHCT_SIZE_BITS 11
#define SHCT_SIZE (1<<SHCT_SIZE_BITS)
#include "hawkeye_predictor.h"
HAWKEYE_IDEALPC_PREDICTOR* demand_predictor;  //Predictor
HAWKEYE_IDEALPC_PREDICTOR* prefetch_predictor;  //Predictor

#include "optgen_simple.h"
OPTgen perset_optgen[LLC_SETS]; // per-set occupancy vectors; we only use 64 of these

#include <math.h>
#define bitmask(l) (((l) == 64) ? (unsigned long long)(-1LL) : ((1LL << (l))-1LL))
#define bits(x, i, l) (((x) >> (i)) & bitmask(l))

#ifdef SAMPLING
    //Sample 64 sets per core
    #define SAMPLED_SET(set) (bits(set, 0 , 6) == bits(set, ((unsigned long long)log2(LLC_SETS) - 6), 6) )
    //#define SAMPLED_SET(set) (bits(set, 0 , 8) == bits(set, ((unsigned long long)log2(LLC_SETS) - 8), 8) )
#else
    #define SAMPLED_SET(set) true
#endif

// Sampler to track 8x cache history for sampled sets
// 2800 entris * 4 bytes per entry = 11.2KB
#define SAMPLED_CACHE_SIZE 2800*NUM_CPUS
map<uint64_t, ADDR_INFO> addr_history; // Sampler

struct TRACE
{
    bool real;
    uint64_t PC;
    uint64_t addr;
    double prob;
    double detrain_prob;
    bool prediction;
    int optgen_result;
    int hawkeye_accurate;
    bool is_prefetch;
    unsigned int interval_type; //00-DD, 01-PD, 02-DP, 03-PP

    TRACE(bool _real, uint64_t _pc, uint64_t _addr, double _prob, double _detrain_prob, bool _is_prefetch, bool _prediction)
    {   
        real = _real;
        PC = _pc;
        addr = _addr;
        prob = _prob;
        detrain_prob = _detrain_prob;
        optgen_result = -1;
        hawkeye_accurate = -1;
        is_prefetch = _is_prefetch;
        prediction = _prediction;
        interval_type = 5;
    }

    void update(bool optgen, bool accurate, bool prefetch_end_point)
    {
        optgen_result = optgen;
        hawkeye_accurate = accurate;
        if(accurate)
            assert(prediction == optgen_result);
        else
            assert(prediction != optgen_result);

        if( !is_prefetch && !prefetch_end_point) interval_type = 0;
        if( is_prefetch && !prefetch_end_point) interval_type = 1;
        if( !is_prefetch && prefetch_end_point) interval_type = 2;
        if( is_prefetch && prefetch_end_point) interval_type = 3;

        assert(interval_type <= 3);
    }

    void print()
    {
        if(optgen_result == -1)
        {
            assert(hawkeye_accurate == -1);
            optgen_result = 0;
            hawkeye_accurate = (prediction == 0);
            interval_type = 5;
        }

        assert(interval_type <= 5);
        
        //cout << real << " " << hex << PC << " " << addr << " " << dec << prob << " " << detrain_prob << " " << optgen_result << " " << hawkeye_accurate << endl;
        cout << hex << PC << " " << addr << " " << dec << " " << is_prefetch << " " << interval_type << " " << optgen_result << " " << hawkeye_accurate << endl;
    }
};

vector<TRACE> trace;

// initialize replacement state
void CACHE::llc_initialize_replacement()
{
    for (int i=0; i<LLC_SETS; i++) {
        for (int j=0; j<LLC_WAYS; j++) {
            rrpv[i][j] = maxRRPV;
            signatures[i][j] = 0;
            addresses[i][j] = 0;
            prefetched[i][j] = false;
        }
        perset_mytimer[i] = 0;
        perset_optgen[i].init(LLC_WAYS-1);
    }

    addr_history.clear();

    demand_predictor = new HAWKEYE_IDEALPC_PREDICTOR();
    prefetch_predictor = new HAWKEYE_IDEALPC_PREDICTOR();
    cout << "Initialize Hawkeye state" << endl;
}

// find replacement victim
// return value should be 0 ~ 15 or 16 (bypass)
uint32_t CACHE::llc_find_victim(uint32_t cpu, uint64_t instr_id, uint32_t set, const BLOCK *current_set, uint64_t ip, uint64_t full_addr, uint32_t type)
{
    // look for the maxRRPV line
    for (uint32_t i=0; i<LLC_WAYS; i++)
        if (rrpv[set][i] == maxRRPV)
            return i;

    //If we cannot find a cache-averse line, we evict the oldest cache-friendly line
    uint32_t max_rrip = 0;
    int32_t lru_victim = -1;
    for (uint32_t i=0; i<LLC_WAYS; i++)
    {
        if (rrpv[set][i] >= max_rrip)
        {
            max_rrip = rrpv[set][i];
            lru_victim = i;
        }
    }

    assert (lru_victim != -1);
    //The predictor is trained negatively on LRU evictions
    if( SAMPLED_SET(set) )
    {
        //double prob = 0;
        //double detrain_prob = 0;
        if(prefetched[set][lru_victim]) 
        {
            //prefetch_predictor->decrement(signatures[set][lru_victim]);
            prefetch_predictor->detrain(signatures[set][lru_victim]);
          //  prob = prefetch_predictor->get_probability(signatures[set][lru_victim]);
          //  detrain_prob = prefetch_predictor->get_detrain_probability(signatures[set][lru_victim]);
        }
        else
        {
            demand_predictor->detrain(signatures[set][lru_victim]);
           // prob = demand_predictor->get_probability(signatures[set][lru_victim]);
           // detrain_prob = demand_predictor->get_detrain_probability(signatures[set][lru_victim]);
        }

        //TRACE input(0, signatures[set][lru_victim], addresses[set][lru_victim], prob, detrain_prob);
        //cout << "0 " << hex << signatures[set][lru_victim] << " " << addresses[set][lru_victim] << dec << " " << prob << " -1 " << -1 << endl;
        //trace.push_back(input);
    }
    return lru_victim;

    // WE SHOULD NOT REACH HERE
    assert(0);
    return 0;
}

void replace_addr_history_element()
{
    uint64_t lru_addr = 0;
    uint64_t lru_time = 10000000;

    for(map<uint64_t, ADDR_INFO>::iterator it=addr_history.begin(); it != addr_history.end(); it++)
    {
        if((it->second).last_quanta < lru_time)
        {
            lru_time =  (it->second).last_quanta;
            lru_addr = it->first;
        }
    }
    assert(lru_addr != 0);
    addr_history.erase(lru_addr);
}

uint64_t timer = 0;

uint64_t average_latency[NUM_CPUS] = {0};
uint64_t average_latency_count[NUM_CPUS] = {0};

// called on every cache hit and cache fill
void CACHE::llc_update_replacement_state(uint32_t cpu, uint32_t set, uint32_t way, uint64_t full_addr, uint64_t ip, uint64_t victim_addr, uint32_t type, uint8_t hit, uint64_t latency, uint64_t effective_latency)
{
    uint64_t paddr = (full_addr >> 6) << 6;

    if(type == PREFETCH)
    {
        if (!hit)
            prefetched[set][way] = true;
    }
    else
        prefetched[set][way] = false;

    //Ignore writebacks
    if (type == WRITEBACK)
        return;

    if(!hit) {
        average_latency[cpu] += latency;
        average_latency_count[cpu] += 1;
    }

    //If we are sampling, OPTgen will only see accesses from sampled sets
    if(SAMPLED_SET(set))
    {
        //The current timestep 
        uint64_t curr_quanta = perset_mytimer[set];

        if((addr_history.find(paddr) != addr_history.end()) && (type != PREFETCH))
        {
            uint64_t last_quanta = addr_history[paddr].last_quanta;
            assert(curr_quanta >= addr_history[paddr].last_quanta);
            bool last_prediction = addr_history[paddr].last_prediction;

            if( perset_optgen[set].should_cache(curr_quanta, last_quanta))
            {
                trace[addr_history[paddr].index].update(1, (last_prediction == 1), (type == PREFETCH));
                if(addr_history[paddr].prefetched)
                    prefetch_predictor->increment(addr_history[paddr].PC);
                else 
                    demand_predictor->increment(addr_history[paddr].PC);
            }
            else
            {
                trace[addr_history[paddr].index].update(0, (last_prediction == 0), (type == PREFETCH));
                if(addr_history[paddr].prefetched) 
                    prefetch_predictor->decrement(addr_history[paddr].PC);
                else 
                    demand_predictor->decrement(addr_history[paddr].PC);
            }
            //Some maintenance operations for OPTgen
            perset_optgen[set].add_access(curr_quanta);

            //Since this was a demand access, mark the prefetched bit as false
            addr_history[paddr].prefetched = false;
        }
        // This is the first time we are seeing this line (could be demand or prefetch)
        else if(addr_history.find(paddr) == addr_history.end())
        {
#ifdef SAMPLING
            // Find a victim from the sampled cache if we are sampling
            assert(addr_history.size() <= SAMPLED_CACHE_SIZE);
            if(addr_history.size() == SAMPLED_CACHE_SIZE) 
                replace_addr_history_element();

            assert(addr_history.size() < SAMPLED_CACHE_SIZE);
#endif
            //Initialize a new entry in the sampler
            addr_history[paddr].init(curr_quanta);
            //If it's a prefetch, mark the prefetched bit;
            if(type == PREFETCH)
                perset_optgen[set].add_prefetch(curr_quanta);
            else
                perset_optgen[set].add_access(curr_quanta);
        }
        else //This line is a prefetch
        {
            assert(addr_history.find(paddr) != addr_history.end());
            uint64_t last_quanta = addr_history[paddr].last_quanta;
            bool last_prediction = addr_history[paddr].last_prediction;

            //if (perset_mytimer[set] - addr_history[paddr].last_quanta < 5*NUM_CPUS) 
            if (true)
            {
                if(perset_optgen[set].should_cache(curr_quanta, last_quanta, true))
                {
                    trace[addr_history[paddr].index].update(1, (last_prediction == 1), (type == PREFETCH));
                    if(addr_history[paddr].prefetched) // P-P
                        prefetch_predictor->increment(addr_history[paddr].PC);
                    else //D-P
                        demand_predictor->increment(addr_history[paddr].PC);
                }
                else
                    trace[addr_history[paddr].index].update(0, (last_prediction == 0), (type == PREFETCH));
            }
            else
                trace[addr_history[paddr].index].update(0, (last_prediction == 0), (type == PREFETCH));

            perset_optgen[set].add_prefetch(curr_quanta);
        }

        double prob = 0, detrain_prob = 0;
        if (type == PREFETCH)
        {   
            prob = prefetch_predictor->get_probability(ip);
            detrain_prob = prefetch_predictor->get_detrain_probability(ip);
        }
        else
        {
            prob = demand_predictor->get_probability(ip);
            detrain_prob = demand_predictor->get_detrain_probability(ip);
        }
         
        // Get Hawkeye's prediction for this line
        bool new_prediction = demand_predictor->get_prediction (ip);
        if (type == PREFETCH)
            new_prediction = prefetch_predictor->get_prediction (ip);

        TRACE input(1, ip, paddr, prob, detrain_prob, (type == PREFETCH), new_prediction);
        uint32_t index = trace.size();
        trace.push_back(input);
 
        // Update the sampler with the timestamp, PC and our prediction
        // For prefetches, the PC will represent the trigger PC
        addr_history[paddr].update(perset_mytimer[set], ip, new_prediction);
        if(type == PREFETCH)
            addr_history[paddr].mark_prefetch(); 
        else
            addr_history[paddr].prefetched = false; 
        addr_history[paddr].lru = 0;
        addr_history[paddr].index = index;

        //Increment the set timer
    }

    perset_mytimer[set] = (perset_mytimer[set]+1);
    bool new_prediction = demand_predictor->get_prediction (ip);
    if (type == PREFETCH)
        new_prediction = prefetch_predictor->get_prediction (ip);

    signatures[set][way] = ip;
    addresses[set][way] = paddr;



    //Set RRIP values and age cache-friendly line
    if(!new_prediction)
        rrpv[set][way] = maxRRPV;
    else
    {
        rrpv[set][way] = 0;
        if(!hit)
        {
            bool saturated = false;
            for(uint32_t i=0; i<LLC_WAYS; i++)
                if (rrpv[set][i] == maxRRPV-1)
                    saturated = true;

            //Age all the cache-friendly  lines
            for(uint32_t i=0; i<LLC_WAYS; i++)
            {
                if (!saturated && rrpv[set][i] < maxRRPV-1)
                    rrpv[set][i]++;
            }
        }
        rrpv[set][way] = 0;
    }
}

// use this function to print out your own stats at the end of simulation
void CACHE::llc_replacement_final_stats()
{

    for(unsigned int i =0; i<trace.size(); i++)
    {
        trace[i].print();
    }

    return ;

    unsigned int hits = 0;
    unsigned int accesses = 0;
    unsigned int traffic = 0;


    for(unsigned int i=0; i<LLC_SETS; i++)
    {
        accesses += perset_optgen[i].access;
        hits += perset_optgen[i].get_num_opt_hits();
        traffic += perset_optgen[i].get_traffic();
    }

    std::cout << "OPTgen accesses: " << accesses << std::endl;
    std::cout << "OPTgen hits: " << hits << std::endl;
    std::cout << "OPTgen hit rate: " << 100*(double)hits/(double)accesses << std::endl;
    std::cout << "Traffic: " << traffic << " " << 100*(double)traffic/(double)accesses << std::endl;

    cout << endl << endl;
    cout << endl << endl;
    for(unsigned int i=0; i<NUM_CPUS; i++)
        cout << "Average latency Core " << i << ": " << (double)average_latency[i]/(double)average_latency_count[i] << endl;
    return;
}
