#include "cache.h"
#include "compression_tracker.h"
#include "counter.h"

#include <iomanip>
#include <stdint.h>
#include <random>
#include <unordered_set>

// Tracker used for printing out compressibility stats.
CompressionTracker compression_tracker;

// The maximum value RRPV can reach in the cache.
#define RRPV_MAX_VALUE (LLC_WAY - 1)

// Number of sets dedicated to a certain policy for set dueling purposes.
#define NUM_LEADER_SETS 32

// BIP keeps an internal, global counter which is incremented on every BIP-cache access;
// BIP does not change RRPV of lines unless the counter equals this interval (after which the
// counter is reset to 0). Thus, BIP only changes a line's RRPV every BIP_INTERVAL accesses.
#define BIP_INTERVAL 32

// Defines the PSEL global performance counter; a low PSEL (0 - PSEL_THRESHOLD - 1) corresponds to SRRIP currently
// performing better, while a high PSEL (PSEL_THRESHOLD - PSEL_MAX) corresponds to BIP currently performing better.
// There is usually one counter per CPU.
#define PSEL_WIDTH 10
#define PSEL_MAX ((1<<PSEL_WIDTH)-1)
#define PSEL_THRESHOLD PSEL_MAX/2

struct CPUInfo {
    // PSEL counter, used for checking which policy performs better for this specific CPU.
    // Low values = SRRIP, High values = BIP.
    Counter<PSEL_MAX> psel;

    // Sets of leaders for SRRIP/BIP (i.e., the sets which are fixed on a policy for set dueling).
    std::unordered_set<uint32_t> srrip_leaders;
    std::unordered_set<uint32_t> bip_leaders;

    CPUInfo() : psel(), srrip_leaders(), bip_leaders() {}
    CPUInfo(std::unordered_set<uint32_t> srrip, std::unordered_set<uint32_t> bip)
        : psel(PSEL_THRESHOLD), srrip_leaders(std::move(srrip)), bip_leaders(std::move(bip)) {}

    // Simple convienence methods which check if a set is a leader.
    bool is_srrip_leader(uint32_t set) { return srrip_leaders.find(set) != srrip_leaders.end(); }
    bool is_bip_leader(uint32_t set) { return bip_leaders.find(set) != bip_leaders.end(); }
};

// RRIP values; global for the cache.
std::array<std::array<uint32_t, LLC_WAY>, LLC_SET> rrpv;

// Global counter for the BIP policy; see BIP_INTERVAL.
uint32_t bip_counter = 0;

// Per-CPU metadata; tracks leader sets and PSEL counter.
std::array<CPUInfo, NUM_CPUS> cpu_info;

/**
 * Called to initialize the LLC replacement policy state.
 */
void CACHE::llc_initialize_replacement() {
    // Randomly generate leader sets; these should be unique across all CPUs/all policies.
    std::unordered_set<uint32_t> all_lead_sets;
    std::mt19937_64 gen;
    std::uniform_int_distribution<> distribution(0, NUM_SET);

    for(int cpu = 0; cpu < NUM_CPUS; cpu++) {
        std::unordered_set<uint32_t> srrip_sets, bip_sets;
        uint32_t lead;

        // TODO: A little messy/code-duplicated, but it's right next to each other so not the most evil.
        // Generate leader sets for SRRIP first.
        for(int set = 0; set < NUM_LEADER_SETS; set++) {
            while(all_lead_sets.find(lead = distribution(gen)) != all_lead_sets.end());
            all_lead_sets.insert(lead);
            srrip_sets.insert(lead);
        }

        // Then leader sets for BIP.
        for(int set = 0; set < NUM_LEADER_SETS; set++) {
            while(all_lead_sets.find(lead = distribution(gen)) != all_lead_sets.end());
            all_lead_sets.insert(lead);
            bip_sets.insert(lead);
        }

        // Initialize actual CPU info.
        cpu_info[cpu] = CPUInfo(std::move(srrip_sets), std::move(bip_sets));
    }

    // Initialize RRPV values.
    for(uint32_t i = 0; i < LLC_SET; i++)
        for(uint32_t j = 0; j < LLC_WAY; j++)
            rrpv[i][j] = RRPV_MAX_VALUE;
}

uint32_t CACHE::llc_find_victim(uint32_t cpu, uint64_t instr_id, uint32_t set, const BLOCK *current_set, uint64_t ip,
    uint64_t full_addr, uint32_t type) {
    std::cerr << "Normal find victim also called..." << std::endl;

    // An assert() is legitimate here instead of an exit(), because this should never happen.
    assert(0);
    return 0;
}

void CACHE::llc_update_replacement_state(uint32_t cpu, uint32_t set, uint32_t way, uint64_t full_addr, uint64_t ip,
    uint64_t victim_addr, uint32_t type, uint8_t hit, uint64_t latency, uint64_t effective_latency) {
    std::cout << "Normal Update replacement state called..." << std::endl;

    // Assert is valid here as this should never happen.
    assert(0);
}

void CACHE::llc_replacement_final_stats() {
    compression_tracker.print();
}

uint32_t CACHE::llc_find_victim_cc(uint32_t cpu, uint64_t instr_id, uint32_t set, const COMPRESSED_CACHE_BLOCK *current_set,
        uint64_t ip, uint64_t full_addr, uint32_t type, uint64_t incoming_cf, uint32_t& evicted_compressed_index) {
    // 1st Variant: Look for empty/invalid space in a superblock line.
    for(uint32_t way = 0; way < LLC_WAY; way++) {
        // Ignore lines w/ a different superblock.
        if(current_set[way].sbTag != get_sb_tag(full_addr >> LOG2_BLOCK_SIZE)) continue;

        // Ignore lines of a different compression factor.
        if(current_set[way].compressionFactor != incoming_cf) continue;

        for(uint32_t compression_index = 0; compression_index < current_set[way].compressionFactor; compression_index++) {
            // Ignore valid lines.
            if(current_set[way].valid[compression_index]) continue;

            // We've found an invalid line, return it.
            evicted_compressed_index = compression_index;
            return way;
        }
    }

    // 2nd Variant: Look for a plain invalid way.
    for(uint32_t way = 0; way < LLC_WAY; way++) {
        // Valid ways have CF > 0.
        if(current_set[way].compressionFactor != 0) continue;

        // Otherwise, we found a line.
        evicted_compressed_index = 4;
        return way;
    }

    // Final Variant: Evict a superblock using RRIP; if no lines are max RRPV value, age until one is.
    // Start by finding max-age line.
    uint32_t victim = 0;
    for(uint32_t way = 1; way < LLC_WAY; way++) {
        if(rrpv[set][way] > rrpv[set][victim]) victim = way;
    }

    // Age lines if victim age is not MAX_RRPV.
    if(rrpv[set][victim] < RRPV_MAX_VALUE) {
        uint32_t age_amount = (RRPV_MAX_VALUE - rrpv[set][victim]);
        for(uint32_t way = 0; way < LLC_WAY; way++)
            rrpv[set][way] += age_amount;
    }

    evicted_compressed_index = 4;
    return victim;
}

void CACHE::llc_update_replacement_state_cc(uint32_t cpu, uint32_t set, uint32_t way, uint32_t compressed_index, uint64_t full_addr,
        uint64_t ip, uint64_t victim_addr, uint32_t type, uint32_t cf, uint8_t hit, uint64_t latency, uint64_t effective_latency) {
    // Do not update replacement state for cache writebacks.
    if (type == WRITEBACK){
        rrpv[set][way] = RRPV_MAX_VALUE - 1;
        return;
    }

    // Track compressibility of lines.
    compression_tracker.increment(cf);

    // CACHE HIT: Hits always result in putting hit line in MRU position.
    if (hit) {
        rrpv[set][way] = 0;
        return;
    }

    // CACHE MISS: apply either SRRIP or BIP as is appropriate.
    CPUInfo& cinfo = cpu_info[cpu];
    if(cinfo.is_srrip_leader(set) || cinfo.psel.value() < PSEL_THRESHOLD) {
        rrpv[set][way] = RRPV_MAX_VALUE - 1;
    } else {
        bip_counter = (bip_counter + 1) % BIP_INTERVAL;

        if(bip_counter == 0) rrpv[set][way] = RRPV_MAX_VALUE - 1;
        else rrpv[set][way] = RRPV_MAX_VALUE;
    }

    // If this is a leader set, move the PSEL counter away from the policy (because we missed).
    if(cinfo.is_srrip_leader(set)) cinfo.psel.increment();
    else if(cinfo.is_bip_leader(set)) cinfo.psel.decrement();
}
