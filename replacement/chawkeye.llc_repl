/**
 * A "compression aware" version of Hawkeye which uses a size-aware OPTgen vector to naively
 * support compressed cache lines.
 */

#include "cache.h"
#include "champsim.h"
#include "instruction.h"
#include "size_aware_optgen.h"
#include "counter.h"

#define COUNTER_MAX_VALUE 15
#define RRPV_MAX_VALUE 15

using namespace std;

/**
 * A structure containing all of the relevant information about a cache access.
 */
struct CacheAccess {
    // The cpu the access originated from.
    uint32_t cpu;

    // The specific set which this access went to.
    uint32_t set;

    // The specific memory address which was accessed.
    uint32_t full_address;

    // The address of the start of the cache line the memory address is a part of.
    uint32_t line_address;

    // The Optgen-specific time quanta that this access occurred at, measured in accesses to that Optgen structure.
    uint32_t optgen_time;

    // The PC which generated this access.
    uint32_t pc;

    // The compression factor of the cache line upon insertion.
    uint32_t cf;

    // The prediction made for this cache access (false for miss, true for hit).
    bool prediction;

    CacheAccess(uint32_t cpu, uint32_t set, uint32_t full_address, uint32_t line_address,
            uint32_t optgen_time, uint32_t pc, uint32_t cf, bool prediction)
        : cpu(cpu), set(set), full_address(full_address), line_address(line_address),
        optgen_time(optgen_time), pc(pc), cf(cf), prediction(prediction) {}

    CacheAccess() {}
};

// A map of address -> full cache accesses which we use in order to compute the optimal solution.
map<uint64_t, CacheAccess> outstanding_accesses;

// A map of PC -> saturating counter which tracks how cache friendly/averse each PC is.
map<uint64_t, Counter<COUNTER_MAX_VALUE>> counters;

// A pair of maps tracking overall training/detraining.
map<uint64_t, uint32_t> pc_training_counts;
map<uint64_t, uint32_t> pc_detraining_counts;

// A per-set collection of OPTgen data structures, used to compute the optimal labels of specific
// cache accesses.
SizeAwareOPTgen optgens[LLC_SET];

// A local "timer" counting the number of accesses to each set/optgen.
uint32_t num_accesses[LLC_SET] = {0};

// The full required state for keeping track of RRPV-based LRU.
uint32_t rrpv[LLC_SET][LLC_WAY] = {0};

// Contains metadata about all of the cache lines in the cache.
// TODO: This is technically redundant with outstanding_accesses.
CacheAccess accesses[LLC_SET][LLC_WAY];

/**
 * Ages the RRPV of all lines by 1 in a set, saturating at RRPV_MAX_VALUE.
 */
void rrpv_age_lines(uint32_t set) {
    // First, see if the cache-friendly lines have already reached the saturation point.
    // If they have, there's nothing for us to do.
    for(uint32_t w = 0; w < LLC_WAY; w++) {
        if(accesses[set][w].prediction && rrpv[set][w] == RRPV_MAX_VALUE - 1)
            return;
    }

    // Otherwise, increment every cache-friendly line by 1.
    for(uint32_t w = 0; w < LLC_WAY; w++)
        if(accesses[set][w].prediction) rrpv[set][w]++;
}

/**
 * Detrain a PC by reducing it's counter.
 */
void pc_detrain(uint64_t pc) {
    if(counters.find(pc) == counters.end())
        counters[pc] = Counter<COUNTER_MAX_VALUE>(COUNTER_MAX_VALUE / 2);

    counters[pc].decrement();
    pc_detraining_counts[pc]++;
}

/**
 * Train a PC by increasing it's counter.
 */
void pc_train(uint64_t pc) {
    if(counters.find(pc) == counters.end())
        counters[pc] = Counter<COUNTER_MAX_VALUE>(COUNTER_MAX_VALUE / 2);

    counters[pc].increment();
    pc_training_counts[pc]++;
}

/**
 * Returns the current bias (positive / (positive + negative)) of a PC.
 */
double pc_bias(uint64_t pc) {
    uint64_t training_count = pc_training_counts[pc];
    uint64_t detraining_count = pc_detraining_counts[pc];
    uint64_t total_count = training_count + detraining_count;

    // A relatively optimistic outlook for PCs we have never trained!
    if(total_count == 0)
        return 1;

    return (double) training_count / (double) total_count;
}

// Called to initialize the LLC replacement policy state.
void CACHE::llc_initialize_replacement() {
    // Initialize our optgen structures.
    for(int x = 0; x < LLC_SET; x++) optgens[x] = SizeAwareOPTgen(LLC_WAY * CACHE_LINE_BYTES);
}

// Called when we need to find a victim to evict in a given set.
// I don't really understand "evicted_cf" - I guess we have to set that ourselves? Yikes.
uint32_t CACHE::llc_find_victim_cc(uint32_t cpu, uint64_t instr_id, uint32_t set, const COMPRESSED_CACHE_BLOCK *current_set,
        uint64_t ip, uint64_t full_addr, uint32_t type, uint64_t cf, uint32_t& evicted_cf) {
    // If there's empty space, return that!
    for(uint32_t w = 0; w < LLC_WAY; w++)
        if(!current_set[w].valid) return w;

    // Tricky detraining #1: Check each cache line, and if we wouldn't cache it now, detrain it.
    // For size aware, we need to make sure to pass the size of the cache line as well, which is just
    // max size divided by compression amount.
    for(uint32_t w = 0; w < LLC_WAY; w++) {
        if(!optgens[set].should_cache(accesses[set][w].optgen_time, num_accesses[set], CACHE_LINE_BYTES / accesses[set][w].cf))
            pc_detrain(accesses[set][w].pc);
    }

    // Now, find the victim to evict by searching for the highest RRPV.
    uint32_t max_rrpv = 0;
    uint32_t victim = 0;
    for(uint32_t w = 0; w < LLC_WAY; w++) {
        if(rrpv[set][w] > max_rrpv) {
            max_rrpv = rrpv[set][w];
            victim = w;
        }
    }

    // Set the evicted compression factor, which is just the CF of the victim.
    evicted_cf = accesses[set][victim].cf;

    // If we find a cache-averse line, we can throw it out immediately!
    if(max_rrpv == RRPV_MAX_VALUE)
        return victim;

    // Otherwise, detrain the cache-friendly line as it betrayed expectations and then throw it out.
    pc_detrain(accesses[set][victim].pc);
    return victim;
}

uint32_t CACHE::llc_find_victim(uint32_t cpu, uint64_t instr_id, uint32_t set, const BLOCK *current_set, uint64_t ip,
    uint64_t full_addr, uint32_t type) {
    std::cout << "Normal find victim also called..." << std::endl;
    exit(1);
    return 0;
}

// Called on every cache hit and cache fill to update the replacement state.
// Note: cf is the "field" within the way, if the given way is compressed.
void CACHE::llc_update_replacement_state_cc(uint32_t cpu, uint32_t set, uint32_t way, uint32_t cf, uint64_t full_addr,
        uint64_t ip, uint64_t victim_addr, uint32_t type, uint8_t hit, uint64_t latency, uint64_t effective_latency) {
    // Writeback hit usually does not update the replacement state, so ignore it.
    if (hit && (type == WRITEBACK))
        return;

    // Compute the address of the corresponding cache line, using that to create the cache access and do all the
    // memory-related operations.
    uint64_t line_addr = full_addr & ~(BLOCK_SIZE - 1);

    // If we've seen an access to this cache line before, then update Optgen and output this cache access.
    auto access_iter = outstanding_accesses.find(line_addr);
    if(access_iter != outstanding_accesses.end()) {
        CacheAccess& access = access_iter->second;

        // Record the access in Optgen to get the hit/miss decision.
        bool decision = optgens[set].try_cache(access.optgen_time, num_accesses[set], CACHE_LINE_BYTES / access.cf);

        // Train this PC up or down in our counters based on the decision.
        if(decision) pc_train(access.pc);
        else pc_detrain(access.pc);
    }

    // Make a prediction based on the current counter values!
    uint32_t counter_value = (counters.find(ip) != counters.end()) ? counters[ip].value() : (COUNTER_MAX_VALUE / 2);
    bool prediction = (counter_value >= COUNTER_MAX_VALUE / 2);

    CacheAccess access = CacheAccess(cpu, set, full_addr, line_addr, num_accesses[set], ip, cf, prediction);

    // Update the state of the newly inserted line, including setting up the RRPV and aging other lines in the cache.
    accesses[set][way] = access;

    if(prediction) {
        rrpv[set][way] = 0;
        if(!hit) rrpv_age_lines(set);
        rrpv[set][way] = 0;
    } else {
        rrpv[set][way] = RRPV_MAX_VALUE;
    }

    // Finally, update the access in the access map so we can observe future reuses.
    outstanding_accesses[line_addr] = access;
    num_accesses[set]++;
}

// called on every cache hit and cache fill
void CACHE::llc_update_replacement_state(uint32_t cpu, uint32_t set, uint32_t way, uint64_t full_addr, uint64_t ip,
    uint64_t victim_addr, uint32_t type, uint8_t hit, uint64_t latency, uint64_t effective_latency) {
    std::cout << "Normal Update replacement state called..." << std::endl;
    exit(1);
}

void CACHE::llc_replacement_final_stats() {
}
