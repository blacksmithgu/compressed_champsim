//Hawkeye Cache Replacement Tool v2.0
//UT AUSTIN RESEARCH LICENSE (SOURCE CODE)
//The University of Texas at Austin has developed certain software and documentation that it desires to
//make available without charge to anyone for academic, research, experimental or personal use.
//This license is designed to guarantee freedom to use the software for these purposes. If you wish to
//distribute or make other use of the software, you may purchase a license to do so from the University of
//Texas.
///////////////////////////////////////////////
//                                            //
//     Hawkeye [Jain and Lin, ISCA' 16]       //
//     Akanksha Jain, akanksha@cs.utexas.edu  //
//                                            //
///////////////////////////////////////////////

// Source code for configs 1 and 2

///////////////////////////////////////////////
// before run, please check
// 1. if #define MULTICORE
// 3. so far, only use optgen_simple.h
///////////////////////////////////////////////

#include "cache.h"
#include <map>
#include <cassert>
#include <math.h>

// if single core, comment the line below
#define MULTICORE
#define HISTORY_LENGTH 20

#ifdef MULTICORE
    #define LLC_SETS LLC_SET
    #define LLC_WAYS LLC_WAY
#else
    #define NUM_CORE 1
    #define LLC_SETS LLC_SET
    #define LLC_WAYS 16
#endif

//3-bit RRIP counters or all lines
#define maxRRPV 7
uint32_t rrpv[LLC_SETS][LLC_WAYS];

#define TIMER_SIZE 1024
uint64_t perset_mytimer[LLC_SETS];

// Signatures for sampled sets; we only use 64 of these
// Budget = 64 sets * 16 ways * 12-bit signature per line = 1.5B
uint64_t signatures[LLC_SETS][LLC_WAYS];
uint64_t addresses[LLC_SETS][LLC_WAYS];

// Hawkeye Predictors for demand and prefetch requests
// Predictor with 2K entries and 5-bit counter per entry
// Budget = 2048*5/8 bytes = 1.2KB
#define MAX_SHCT 31

#ifdef MULTICORE
    #define SHCT_SIZE_BITS 14
#else
    #define SHCT_SIZE_BITS 11
#endif

#define SHCT_SIZE (1<<SHCT_SIZE_BITS)

#define OPTGEN_VECTOR_SIZE 128
#include "optgen_crc.h"

#include "hawkeye_predictor_confidence.h"
MULTI_CORE_MULTIPLE_PERCEPTRON_PREDICTOR* demand_predictor;

// we are comparing 3 predictors with different thresholds and adjust their thresholds dynamically
int num_agent = 3;
#define middle_RRPV 4
// middle_RRPV is the first parameter concerning confidence
OPTgen perset_optgen[LLC_SETS]; // per-set occupancy vectors; we only use 64 of these

#define bitmask(l) (((l) == 64) ? (unsigned long long)(-1LL) : ((1LL << (l))-1LL))
#define bits(x, i, l) (((x) >> (i)) & bitmask(l))

#define SAMPLING
//Sample 64 sets per core
#ifdef SAMPLING
    #ifdef MULTICORE
        #define SAMPLED_SET(set) (bits(set, 0 , 8) == bits(set, ((unsigned long long)log2(LLC_SETS) - 8), 8) )
    #else
        #define SAMPLED_SET(set) (bits(set, 0 , 6) == bits(set, ((unsigned long long)log2(LLC_SETS) - 6), 6) )
    #endif
#else
    #define SAMPLED_SET(set) (true)
#endif

// Sampler to track 8x cache history for sampled sets
// 2800 entris * 4 bytes per entry = 11.2KB
#ifdef MULTICORE
    #define SAMPLED_CACHE_SIZE 2800*NUM_CPUS
#else
    #define SAMPLED_CACHE_SIZE 2800
#endif

map<uint64_t, ADDR_INFO> addr_history; // Sampler
unsigned int hit_accurate[NUM_CPUS], hit_inaccurate[NUM_CPUS];
unsigned int miss_accurate[NUM_CPUS], miss_inaccurate[NUM_CPUS];
int num_train;
int evicted_by_wb[NUM_CPUS];
int num_detraining[NUM_CPUS], num_correct_detraining[NUM_CPUS], num_wrong_detraining[NUM_CPUS];
int num_practical_hits[NUM_CPUS], num_optimal_hits[NUM_CPUS], num_both_hits[NUM_CPUS];

vector<uint64_t> curr_histories[NUM_CPUS];

// initialize replacement state
void CACHE::llc_initialize_replacement()
{
    for (int i=0; i<LLC_SETS; i++) {
        for (int j=0; j<LLC_WAYS; j++) {
            rrpv[i][j] = maxRRPV;
            signatures[i][j] = 0;
            addresses[i][j] = 0;
        }
        perset_mytimer[i] = 0;
        perset_optgen[i].init(LLC_WAYS-2);
    }

    addr_history.clear();

    for(int i = 0; i < NUM_CPUS; i++)
    {
        curr_histories[i].clear();
        hit_accurate[i] = 0;
        hit_inaccurate[i] = 0;
        miss_accurate[i] = 0;
        miss_inaccurate[i] = 0;
        evicted_by_wb[i] = 0;
        num_detraining[i] = 0;
        num_correct_detraining[i] = 0;
        num_wrong_detraining[i] = 0;
        num_practical_hits[i] = 0;
        num_optimal_hits[i] = 0;
        num_both_hits[i] = 0;
    }

    demand_predictor = new MULTI_CORE_MULTIPLE_PERCEPTRON_PREDICTOR(NUM_CPUS, num_agent);
    
    num_train = 0;

    cout << "Initialize Hawkeye state" << endl;
    cout << "number of CPUS: " << NUM_CPUS << endl;
    cout << "SHCT_SIZE_BITS: " << SHCT_SIZE_BITS << endl;
}

// find replacement victim
// return value should be 0 ~ 15 or 16 (bypass)
uint32_t CACHE::llc_find_victim(uint32_t cpu, uint64_t instr_id, uint32_t set, const BLOCK *current_set, uint64_t ip, uint64_t full_addr, uint32_t type)
{
    // look for the maxRRPV line
    for (uint32_t i=0; i<LLC_WAYS; i++){
        if (rrpv[set][i] == maxRRPV)
            return i;
    }
    //If we cannot find a cache-averse line, we evict the oldest cache-friendly line
    uint32_t max_rrip = 0;
    int32_t lru_victim = -1;
    for (uint32_t i=0; i<LLC_WAYS; i++)
    {
        if (rrpv[set][i] >= max_rrip)
        {
            max_rrip = rrpv[set][i];
            lru_victim = i;
        }
    }

    assert (lru_victim != -1);
    //The predictor is trained negatively on LRU evictions
    if( SAMPLED_SET(set) )
    {
        assert(addresses[set][lru_victim] != 0);
        if(addr_history.find(addresses[set][lru_victim]) == addr_history.end())
            ;
        else
        {
            uint64_t private_cpu = addr_history[addresses[set][lru_victim]].cpu;
            demand_predictor->single_core_predictors[private_cpu]->decrement(
                signatures[set][lru_victim], 
                addr_history[addresses[set][lru_victim]].context, 
                addresses[set][lru_victim], 
                addr_history[addresses[set][lru_victim]].prev_result, 
                addr_history[addresses[set][lru_victim]].detrained);
            // count writebacks
            if (type == WRITEBACK)
                evicted_by_wb[private_cpu]++;
            
            // assumes it is a miss for the cpu being evicted
            if(warmup_complete[private_cpu])
            {
                if(addr_history[addresses[set][lru_victim]].last_prediction == 0)
                    miss_accurate[private_cpu]++;
                else
                    miss_inaccurate[private_cpu]++;
            }

            num_detraining[private_cpu]++;
  
            addr_history[addresses[set][lru_victim]].detrained = true;
        }  
    }
    return lru_victim;

    // WE SHOULD NOT REACH HERE
    assert(0);
    return 0;
}

void replace_addr_history_element()
{
    uint64_t lru_addr = 0;
    uint64_t lru_time = 10000000;
    
    for(map<uint64_t, ADDR_INFO>::iterator it=addr_history.begin(); it != addr_history.end(); it++)
    {
        if((it->second).last_quanta < lru_time)
        {
            lru_time =  (it->second).last_quanta;
            lru_addr = it->first;
        }
    }
    assert(lru_addr != 0);
    addr_history.erase(lru_addr);
}

// called on every cache hit and cache fill
void CACHE::llc_update_replacement_state(uint32_t cpu, uint32_t set, uint32_t way, uint64_t full_addr, uint64_t ip, uint64_t victim_addr, uint32_t type, uint8_t hit, uint64_t latency, uint64_t effective_latency)
{
    uint64_t paddr = (full_addr >> 6) << 6;
    if (type == WRITEBACK)
    {
        if(!hit)
        {
            //rrpv[set][way] = maxRRPV-1;
            //rrpv[set][way] = maxRRPV;
            //addresses[set][way] = paddr;
        }
        return;
    }

    //If we are sampling, OPTgen will only see accesses from sampled sets
    if(SAMPLED_SET(set))
    {
        //The current timestep 
        uint64_t curr_quanta = perset_mytimer[set] % OPTGEN_VECTOR_SIZE;
        // This line has been used before. Since the right end of a usage interval is always 
        //a demand, ignore prefetches
        if(addr_history.find(paddr) != addr_history.end())
        {
            //Ugliness to take care of the wrapped around liveness vevtor
            unsigned int curr_timer = perset_mytimer[set];
            if(curr_timer < addr_history[paddr].last_quanta)
               curr_timer = curr_timer + TIMER_SIZE;
            bool wrap =  ((curr_timer - addr_history[paddr].last_quanta) > OPTGEN_VECTOR_SIZE);
            uint64_t last_quanta = addr_history[paddr].last_quanta % OPTGEN_VECTOR_SIZE;
            //assert(curr_quanta >= addr_history[paddr].last_quanta);

            //Train the predictor positively because OPT would have cached this line
            if(hit)
                num_practical_hits[cpu]++;

            //if we see a reuse, we reverse the effect of previous detraining based on the last prediction
            //no matter whether should be cached
            if(warmup_complete[cpu])
            {
                if(addr_history[paddr].detrained)
                {
                    if(addr_history[paddr].last_prediction == 0)
                        miss_accurate[cpu]--;
                    else
                        miss_inaccurate[cpu]--;
                }
            }

            if( !wrap && perset_optgen[set].should_cache(curr_quanta, last_quanta))
            {
                num_optimal_hits[cpu]++;
                if(hit)
                    num_both_hits[cpu]++;

                if(addr_history[paddr].detrained)
                    num_wrong_detraining[cpu]++;
              
                if(warmup_complete[cpu])
                {
                    if(addr_history[paddr].last_prediction > 0)
                        hit_accurate[cpu]++;                        
                    else
                        hit_inaccurate[cpu]++;
                }

                demand_predictor->single_core_predictors[cpu]->increment(
                    addr_history[paddr].PC, 
                    addr_history[paddr].context, 
                    paddr,
                    addr_history[paddr].prev_result, 
                    addr_history[paddr].detrained);

                num_train++;

            }
            else
            {
                if(addr_history[paddr].detrained)
                    num_correct_detraining[cpu]++;
                
                if(warmup_complete[cpu])
                {
                    if(addr_history[paddr].last_prediction == 0)
                        miss_accurate[cpu]++;
                    else
                        miss_inaccurate[cpu]++;
                }
                // Train the predictor negatively because OPT would not have cached this line
                demand_predictor->single_core_predictors[cpu]->decrement(
                    addr_history[paddr].PC, 
                    addr_history[paddr].context, 
                    paddr, 
                    addr_history[paddr].prev_result, 
                    addr_history[paddr].detrained);

                num_train++;
            }
            //Some maintenance operations for OPTgen
            perset_optgen[set].add_access(curr_quanta);
        }
        // This is the first time we are seeing this line
        else
        {
#ifdef SAMPLING
            // Find a victim from the sampled cache if we are sampling
            assert(addr_history.size() <= SAMPLED_CACHE_SIZE);
            if(addr_history.size() == SAMPLED_CACHE_SIZE) 
                replace_addr_history_element();
            assert(addr_history.size() < SAMPLED_CACHE_SIZE);
#endif
            //Initialize a new entry in the sampler
            addr_history[paddr].init(curr_quanta);
            perset_optgen[set].add_access(curr_quanta);
        }

        // Get Hawkeye's prediction for this line
        Result result = demand_predictor->single_core_predictors[cpu]->get_prediction(ip, curr_histories[cpu], paddr);
            
        // Update the sampler with the timestamp, PC and our prediction
        // For prefetches, the PC will represent the trigger PC
        addr_history[paddr].update(perset_mytimer[set], ip, result.prediction[result.current]);
        //addr_history[paddr].update(perset_mytimer[set], ip, new_prediction);
        addr_history[paddr].lru = 0;
        addr_history[paddr].context = curr_histories[cpu];
        addr_history[paddr].detrained = false;
        addr_history[paddr].prev_result = result;
        addr_history[paddr].cpu = cpu;
        
        //Increment the set timer
        perset_mytimer[set] = (perset_mytimer[set]+1) % TIMER_SIZE;
    }

    Result result = demand_predictor->single_core_predictors[cpu]->get_prediction(ip, curr_histories[cpu], paddr);
    int new_prediction = result.prediction[result.current];

    signatures[set][way] = ip;
    addresses[set][way] = paddr;   

    assert(curr_histories[cpu].size() <= HISTORY_LENGTH);
    curr_histories[cpu].push_back(ip);
    if(curr_histories[cpu].size() > HISTORY_LENGTH)
        curr_histories[cpu].erase(curr_histories[cpu].begin());
    assert(curr_histories[cpu].size() <= HISTORY_LENGTH);

    //Set RRIP values and age cache-friendly line
    if(new_prediction == 0)
        rrpv[set][way] = maxRRPV;
    else
    {
        rrpv[set][way] = 0;
        if(!hit)
        {
            bool saturated = false;
            for(uint32_t i=0; i<LLC_WAYS; i++)
                if (rrpv[set][i] == maxRRPV-1)
                    saturated = true;

            //Age all the cache-friendly lines
            for(uint32_t i=0; i<LLC_WAYS; i++)
            {
                if (!saturated && rrpv[set][i] < maxRRPV-1)
                    rrpv[set][i]++;
            }
        }
        //=============RRPV modifications================
        if(new_prediction == 1) // predictor is not confident about this
            rrpv[set][way] = middle_RRPV;
        else if(new_prediction == 2) // predictor is quite confident about this
            rrpv[set][way] = 0;
        else //shouldn't arrive here, only two possible RRPV values for cache-friendly lines
            assert(0);
        //=============RRPV modifications================
    }
}

// use this function to print out your own stats at the end of simulation
void CACHE::llc_replacement_final_stats()
{
    unsigned int hits = 0;
    unsigned int accesses = 0;
    //unsigned int traffic = 0;
    for(unsigned int i=0; i<LLC_SETS; i++)
    {
        accesses += perset_optgen[i].access;
        hits += perset_optgen[i].get_num_opt_hits();
     //   traffic += perset_optgen[i].get_traffic();
    }

    std::cout << "OPTgen accesses: " << accesses << std::endl;
    std::cout << "OPTgen hits: " << hits << std::endl;
    std::cout << "OPTgen hit rate: " << 100*(double)hits/(double)accesses << std::endl;
    //std::cout << "Traffic: " << traffic << " " << 100*(double)traffic/(double)accesses << std::endl;

    for(int i = 0; i < NUM_CPUS; i++)
    {
        cout << "CPU: " << i << endl;
        cout << "predicted friendly lines by writebacks: " << evicted_by_wb[i] << endl;

        int num_interval = demand_predictor->single_core_predictors[i]->num_intervals;        
        double* past_threshold = demand_predictor->single_core_predictors[i]->past_thresholds;
    
        // cout << endl;
        // cout << "both hits: " << num_both_hits[i] << endl;
        // cout << "practical hits: " << num_practical_hits[i] << endl;
        // cout << "optimal hits: " << num_optimal_hits[i] << endl;
        // cout << "both hit / practical Ratio: " << 100 * (double)num_both_hits[i] / (double)num_practical_hits[i] << endl;
        // cout << "both hit / optimal Ratio: " << 100 * (double)num_both_hits[i] / (double)num_optimal_hits[i] << endl;
        // cout << endl;
        
        // cout << "detraining: " << num_detraining[i] << endl;
        // cout << "correct detraining: " << num_correct_detraining[i] << endl;
        // cout << "correct detraining Ratio: " << 100 * (double)num_correct_detraining[i] / (double)num_detraining[i] << endl;
        // cout << "wrong detraining: " << num_wrong_detraining[i] << endl;
        // cout << "wrong detraining Ratio: " << 100 * (double)num_wrong_detraining[i] / (double)num_detraining[i] << endl;
        // cout << endl;

        cout << "hit accuracy: " << 100*(double)hit_accurate[i] / (double)(hit_accurate[i] + hit_inaccurate[i]) << endl;
        cout << "total ground truth hit: " << (hit_accurate[i] + hit_inaccurate[i]) << endl; 
        cout << "miss ccuracy: " << 100*(double)miss_accurate[i] / (double)(miss_accurate[i] + miss_inaccurate[i]) << endl;
        cout << "total ground truth miss: " << (miss_accurate[i] + miss_inaccurate[i]) << endl;
        
        cout << "overall accuracy: " << 100*(double)(hit_accurate[i]+miss_accurate[i]) / (double)(hit_accurate[i] + hit_inaccurate[i] + miss_accurate[i] + miss_inaccurate[i]) << endl;

        cout << "threshold history: " << endl;
        for(int j = 0; j < num_interval; j++)
            cout << past_threshold[j] << " ";
        cout << endl << endl;

        // now we want to see the accuracy of predictions of different confidence
        // it's distribution, not cdf
        // we divide the range below threshold into 20 intervals, with 1/20 * threshold as step
        // divide the range above threshold into 30 intervals, this is not that important
        cout << "accuracy distribution over confidence: " << endl;
        double* confidence_up = demand_predictor->single_core_predictors[i]->confidence_histogram_up;
        double* confidence_down = demand_predictor->single_core_predictors[i]->confidence_histogram_down;
        for(int j = 0; j < 51; j++)
        {
            cout << confidence_up[j] / confidence_down[j] << " = " << confidence_up[j] << " / " << confidence_down[j] << endl;
            if(j == 19)
                cout << endl;
        }
    }

    cout << "number of training: " << num_train << endl;
    cout << endl << endl;
    return;
}
