//Hawkeye Cache Replacement Tool v2.0
//UT AUSTIN RESEARCH LICENSE (SOURCE CODE)
//The University of Texas at Austin has developed certain software and documentation that it desires to
//make available without charge to anyone for academic, research, experimental or personal use.
//This license is designed to guarantee freedom to use the software for these purposes. If you wish to
//distribute or make other use of the software, you may purchase a license to do so from the University of
//Texas.
///////////////////////////////////////////////
//                                            //
//     Hawkeye [Jain and Lin, ISCA' 16]       //
//     Akanksha Jain, akanksha@cs.utexas.edu  //
//                                            //
///////////////////////////////////////////////

// Source code for configs 1 and 2

///////////////////////////////////////////////
// before run, please check
// 1. if #define MULTICORE
// 3. so far, only use optgen_simple.h
///////////////////////////////////////////////

#include "cache.h"
#include <map>
#include <cassert>
#include <math.h>

// if single core, comment the line below
//#define MULTICORE
#define HISTORY_LENGTH 20

#ifdef MULTICORE
    #define LLC_SETS LLC_SET
    #define LLC_WAYS LLC_WAY
#else
    #define NUM_CORE 1
    #define LLC_SETS LLC_SET
    #define LLC_WAYS 16
#endif

//3-bit RRIP counters or all lines
#define maxRRPV 7
uint32_t rrpv[LLC_SETS][LLC_WAYS];

#define TIMER_SIZE 1024
uint64_t perset_mytimer[LLC_SETS];

// Signatures for sampled sets; we only use 64 of these
// Budget = 64 sets * 16 ways * 12-bit signature per line = 1.5B
uint64_t signatures[LLC_SETS][LLC_WAYS];
uint64_t addresses[LLC_SETS][LLC_WAYS];

// Hawkeye Predictors for demand and prefetch requests
// Predictor with 2K entries and 5-bit counter per entry
// Budget = 2048*5/8 bytes = 1.2KB
#define MAX_SHCT 31

#ifdef MULTICORE
    #define SHCT_SIZE_BITS 14
#else
    #define SHCT_SIZE_BITS 11
#endif

#define SHCT_SIZE (1<<SHCT_SIZE_BITS)

#define OPTGEN_VECTOR_SIZE 128
#include "optgen_crc.h"

#include "hawkeye_predictor_confidence.h"
MULTI_CORE_MULTIPLE_PERCEPTRON_PREDICTOR* demand_predictor;

// we are comparing 3 predictors with different thresholds and adjust their thresholds dynamically
int num_agent = 3;
#define middle_RRPV 4
// middle_RRPV is the first parameter concerning confidence
OPTgen perset_optgen[LLC_SETS]; // per-set occupancy vectors; we only use 64 of these

#define bitmask(l) (((l) == 64) ? (unsigned long long)(-1LL) : ((1LL << (l))-1LL))
#define bits(x, i, l) (((x) >> (i)) & bitmask(l))

#define SAMPLING
//Sample 64 sets per core
#ifdef SAMPLING
    #ifdef MULTICORE
        #define SAMPLED_SET(set) (bits(set, 0 , 8) == bits(set, ((unsigned long long)log2(LLC_SETS) - 8), 8) )
    #else
        #define SAMPLED_SET(set) (bits(set, 0 , 6) == bits(set, ((unsigned long long)log2(LLC_SETS) - 6), 6) )
    #endif
#else
    #define SAMPLED_SET(set) (true)
#endif

// Sampler to track 8x cache history for sampled sets
// 2800 entris * 4 bytes per entry = 11.2KB
#ifdef MULTICORE
    #define SAMPLED_CACHE_SIZE 2800*NUM_CPUS
#else
    #define SAMPLED_CACHE_SIZE 2800
#endif

#define SAMPLER_WAYS 8
#define SAMPLER_SETS SAMPLED_CACHE_SIZE/SAMPLER_WAYS

vector<map<uint64_t, ADDR_INFO> > addr_history; // Sampler
unsigned int hit_accurate[NUM_CPUS], hit_inaccurate[NUM_CPUS];
unsigned int miss_accurate[NUM_CPUS], miss_inaccurate[NUM_CPUS];
unsigned int no_feedback_accurate[NUM_CPUS], no_feedback_inaccurate[NUM_CPUS];
unsigned int hit_predictions[NUM_CPUS], miss_predictions[NUM_CPUS];

struct PCSTATS
{
    unsigned int hit_accurate, miss_accurate, hit_inaccurate, miss_inaccurate;
    unsigned int no_feedback_accurate, no_feedback_inaccurate;
    unsigned int hit_predictions, miss_predictions;

    void init()
    {
        hit_accurate = 0;
        hit_inaccurate = 0;
        miss_accurate = 0;
        miss_inaccurate = 0;
        no_feedback_accurate = 0;
        no_feedback_inaccurate = 0;
        hit_predictions = 0;
        miss_predictions = 0;
    }

    unsigned int accesses()
    {
        return (hit_predictions + miss_predictions);
        //return (hit_accurate + miss_accurate + no_feedback_accurate + hit_inaccurate + miss_inaccurate + no_feedback_inaccurate);
    }
        
    double feedback_accuracy()
    {
        return 100*(double)(hit_accurate + miss_accurate)/(double)(hit_accurate + miss_accurate + hit_inaccurate + miss_inaccurate);
    }

    double total_accuracy()
    {   
        assert(no_feedback_accurate == 0);
        no_feedback_accurate = miss_predictions - miss_accurate - hit_inaccurate;
        assert(miss_predictions >= (miss_accurate + hit_inaccurate));
        //cout << endl << "****" << miss_predictions << " " << miss_accurate << " " << miss_inaccurate << "*****" << endl;
        return 100*(double)(hit_accurate + miss_accurate + no_feedback_accurate)/(double)(hit_accurate + miss_accurate + hit_inaccurate + miss_inaccurate + no_feedback_accurate + no_feedback_inaccurate);
    }

    void print()
    {
        cout << feedback_accuracy() << " " << total_accuracy() << " -- " << 100*(double)hit_accurate/(double)(hit_accurate + hit_inaccurate) << " " << 100*(double)miss_accurate/(double)(miss_accurate + miss_inaccurate) << " " << (double)no_feedback_accurate/(double)(no_feedback_accurate + no_feedback_inaccurate) << " -- " << (hit_accurate + hit_inaccurate) << " " << (miss_accurate + miss_inaccurate) << " " << (no_feedback_accurate + no_feedback_inaccurate) << endl;
    }
};

map<uint64_t, PCSTATS> per_pc_stats;

int num_train;
int evicted_by_wb[NUM_CPUS];
int num_detraining[NUM_CPUS], num_correct_detraining[NUM_CPUS], num_wrong_detraining[NUM_CPUS];
int num_practical_hits[NUM_CPUS], num_optimal_hits[NUM_CPUS], num_both_hits[NUM_CPUS];

vector<uint64_t> curr_histories[NUM_CPUS];

// initialize replacement state
void CACHE::llc_initialize_replacement()
{
    for (int i=0; i<LLC_SETS; i++) {
        for (int j=0; j<LLC_WAYS; j++) {
            rrpv[i][j] = maxRRPV;
            signatures[i][j] = 0;
            addresses[i][j] = 0;
        }
        perset_mytimer[i] = 0;
        perset_optgen[i].init(LLC_WAYS-2);
    }

    addr_history.resize(SAMPLER_SETS);
    for (int i=0; i<SAMPLER_SETS; i++) 
        addr_history[i].clear();

    for(int i = 0; i < NUM_CPUS; i++)
    {
        curr_histories[i].clear();
        hit_accurate[i] = 0;
        hit_inaccurate[i] = 0;
        miss_accurate[i] = 0;
        miss_inaccurate[i] = 0;
        hit_predictions[i] = 0;
        miss_predictions[i] = 0;
        no_feedback_accurate[i] = 0;
        no_feedback_inaccurate[i] = 0;
        evicted_by_wb[i] = 0;
        num_detraining[i] = 0;
        num_correct_detraining[i] = 0;
        num_wrong_detraining[i] = 0;
        num_practical_hits[i] = 0;
        num_optimal_hits[i] = 0;
        num_both_hits[i] = 0;
    }

    demand_predictor = new MULTI_CORE_MULTIPLE_PERCEPTRON_PREDICTOR(NUM_CPUS, num_agent);
    
    num_train = 0;

    cout << "Initialize Hawkeye state" << endl;
    cout << "number of CPUS: " << NUM_CPUS << endl;
    cout << "SHCT_SIZE_BITS: " << SHCT_SIZE_BITS << endl;
}

// find replacement victim
// return value should be 0 ~ 15 or 16 (bypass)
uint32_t CACHE::llc_find_victim(uint32_t cpu, uint64_t instr_id, uint32_t set, const BLOCK *current_set, uint64_t ip, uint64_t full_addr, uint32_t type)
{
    // look for the maxRRPV line
    for (uint32_t i=0; i<LLC_WAYS; i++)
        if (rrpv[set][i] == maxRRPV)
            return i;

    //If we cannot find a cache-averse line, we evict the oldest cache-friendly line
    uint32_t max_rrip = 0;
    int32_t lru_victim = -1;
    for (uint32_t i=0; i<LLC_WAYS; i++)
    {
        if (rrpv[set][i] >= max_rrip)
        {
            max_rrip = rrpv[set][i];
            lru_victim = i;
        }
    }

    assert (lru_victim != -1);
    //The predictor is trained negatively on LRU evictions
    if( SAMPLED_SET(set) )
    {
        uint32_t sampler_set = ((addresses[set][lru_victim]) >> 6) % SAMPLER_SETS; 
        //uint64_t sampler_tag = CRC((addresses[set][lru_victim]) >> 12) % 256;
        uint64_t sampler_tag = (addresses[set][lru_victim]);

        //assert(addresses[set][lru_victim] != 0);
        assert(sampler_set < SAMPLER_SETS);
        if(addr_history[sampler_set].find(sampler_tag) != addr_history[sampler_set].end())
        {
            uint64_t private_cpu = addr_history[sampler_set][sampler_tag].cpu;
            assert(addr_history[sampler_set][sampler_tag].last_prediction != 0);
            assert(addr_history[sampler_set][sampler_tag].PC == signatures[set][lru_victim]);

            demand_predictor->single_core_predictors[private_cpu]->decrement(
                signatures[set][lru_victim], 
                addr_history[sampler_set][sampler_tag].context, 
                addresses[set][lru_victim], 
                addr_history[sampler_set][sampler_tag].prev_result, 
                addr_history[sampler_set][sampler_tag].detrained);
            // count writebacks
            if (type == WRITEBACK)
                evicted_by_wb[private_cpu]++;
            
            // assumes it is a miss for the cpu being evicted
            //if(warmup_complete[private_cpu])
            //{
            assert(per_pc_stats.find(signatures[set][lru_victim]) != per_pc_stats.end());
            if(addr_history[sampler_set][sampler_tag].last_prediction == 0)
            {
                assert(0);
                no_feedback_accurate[private_cpu]++;
                per_pc_stats[signatures[set][lru_victim]].no_feedback_accurate++;
            }
            else
            {
                no_feedback_inaccurate[private_cpu]++;
                per_pc_stats[signatures[set][lru_victim]].no_feedback_inaccurate++;
            }
            //}

            num_detraining[private_cpu]++;
  
            addr_history[sampler_set][sampler_tag].detrained = true;
        }  
    }
    return lru_victim;

    // WE SHOULD NOT REACH HERE
    assert(0);
    return 0;
}

void replace_addr_history_element(unsigned int sampler_set)
{
    uint64_t lru_addr = 0;
    
    for(map<uint64_t, ADDR_INFO>::iterator it=addr_history[sampler_set].begin(); it != addr_history[sampler_set].end(); it++)
    {
   //     uint64_t timer = (it->second).last_quanta;

        if((it->second).lru == (SAMPLER_WAYS-1))
        {
            //lru_time =  (it->second).last_quanta;
            lru_addr = it->first;
            break;
        }
    }

    addr_history[sampler_set].erase(lru_addr);
}

void update_addr_history_lru(unsigned int sampler_set, unsigned int curr_lru)
{
    for(map<uint64_t, ADDR_INFO>::iterator it=addr_history[sampler_set].begin(); it != addr_history[sampler_set].end(); it++)
    {
        if((it->second).lru < curr_lru)
        {
            (it->second).lru++;
            assert((it->second).lru < SAMPLER_WAYS); 
        }
    }
}


// called on every cache hit and cache fill
void CACHE::llc_update_replacement_state(uint32_t cpu, uint32_t set, uint32_t way, uint64_t full_addr, uint64_t ip, uint64_t victim_addr, uint32_t type, uint8_t hit, uint64_t latency, uint64_t effective_latency)
{
    uint64_t paddr = (full_addr >> 6) << 6;
    if (type == WRITEBACK)
    {
        if(!hit)
        {
            //rrpv[set][way] = maxRRPV-1;
            //rrpv[set][way] = maxRRPV;
            addresses[set][way] = 0;
            signatures[set][way] = 0;
        }

        return;
    }


    //If we are sampling, OPTgen will only see accesses from sampled sets
    if(SAMPLED_SET(set))
    {
    cout << set << " " << hex << paddr << dec;
        //The current timestep 
        uint64_t curr_quanta = perset_mytimer[set] % OPTGEN_VECTOR_SIZE;

        uint32_t sampler_set = (paddr >> 6) % SAMPLER_SETS; 
        //uint64_t sampler_tag = CRC(paddr >> 12) % 256;
        uint64_t sampler_tag = paddr;
        assert(sampler_set < SAMPLER_SETS);

        // This line has been used before. Since the right end of a usage interval is always 
        //a demand, ignore prefetches
        if(addr_history[sampler_set].find(sampler_tag) != addr_history[sampler_set].end())
        {
            //Ugliness to take care of the wrapped around liveness vevtor
            unsigned int curr_timer = perset_mytimer[set];
            if(curr_timer < addr_history[sampler_set][sampler_tag].last_quanta)
               curr_timer = curr_timer + TIMER_SIZE;
            bool wrap =  ((curr_timer - addr_history[sampler_set][sampler_tag].last_quanta) > OPTGEN_VECTOR_SIZE);
            uint64_t last_quanta = addr_history[sampler_set][sampler_tag].last_quanta % OPTGEN_VECTOR_SIZE;

            //Train the predictor positively because OPT would have cached this line
            if(hit)
                num_practical_hits[cpu]++;

            //if we see a reuse, we reverse the effect of previous detraining based on the last prediction
            //no matter whether should be cached
            //if(warmup_complete[cpu])
            //{
            if(addr_history[sampler_set][sampler_tag].detrained)
            {
                assert(per_pc_stats.find(addr_history[sampler_set][sampler_tag].PC) != per_pc_stats.end());
                if(addr_history[sampler_set][sampler_tag].last_prediction == 0)
                {
                    assert(0);
                    no_feedback_accurate[cpu]--;
                    per_pc_stats[addr_history[sampler_set][sampler_tag].PC].no_feedback_accurate--;
                }
                else
                {
                    assert(no_feedback_inaccurate[cpu] > 0);
                    no_feedback_inaccurate[cpu]--;
                    assert(per_pc_stats[addr_history[sampler_set][sampler_tag].PC].no_feedback_inaccurate > 0);
                    per_pc_stats[addr_history[sampler_set][sampler_tag].PC].no_feedback_inaccurate--;
                }
            }
            //}

            if( !wrap && perset_optgen[set].should_cache(curr_quanta, last_quanta))
            {
                cout << dec << " 1";
                num_optimal_hits[cpu]++;
                if(hit)
                    num_both_hits[cpu]++;

                if(addr_history[sampler_set][sampler_tag].detrained)
                    num_wrong_detraining[cpu]++;
              
                //if(warmup_complete[cpu])
                //{
                    assert(per_pc_stats.find(addr_history[sampler_set][sampler_tag].PC) != per_pc_stats.end());
                    if(addr_history[sampler_set][sampler_tag].last_prediction > 0) 
                    {
                        hit_accurate[cpu]++;                        
                        per_pc_stats[addr_history[sampler_set][sampler_tag].PC].hit_accurate++;
                    }
                    else
                    {
                        hit_inaccurate[cpu]++;
                        per_pc_stats[addr_history[sampler_set][sampler_tag].PC].hit_inaccurate++;
                    }
                //}

                demand_predictor->single_core_predictors[cpu]->increment(
                    addr_history[sampler_set][sampler_tag].PC, 
                    addr_history[sampler_set][sampler_tag].context, 
                    paddr,
                    addr_history[sampler_set][sampler_tag].prev_result, 
                    addr_history[sampler_set][sampler_tag].detrained);

                num_train++;

            }
            else
            {
                cout << dec << " 0";
                if(addr_history[sampler_set][sampler_tag].detrained)
                    num_correct_detraining[cpu]++;
                
                //if(warmup_complete[cpu])
                //{
                    assert(per_pc_stats.find(addr_history[sampler_set][sampler_tag].PC) != per_pc_stats.end());
                    if(addr_history[sampler_set][sampler_tag].last_prediction == 0)
                    {
                        miss_accurate[cpu]++;
                        per_pc_stats[addr_history[sampler_set][sampler_tag].PC].miss_accurate++;
                    }
                    else
                    {
                        miss_inaccurate[cpu]++;
                        per_pc_stats[addr_history[sampler_set][sampler_tag].PC].miss_inaccurate++;
                    }
                //}
                // Train the predictor negatively because OPT would not have cached this line
                demand_predictor->single_core_predictors[cpu]->decrement(
                    addr_history[sampler_set][sampler_tag].PC, 
                    addr_history[sampler_set][sampler_tag].context, 
                    paddr, 
                    addr_history[sampler_set][sampler_tag].prev_result, 
                    addr_history[sampler_set][sampler_tag].detrained);

                num_train++;
            }
            //Some maintenance operations for OPTgen
            perset_optgen[set].add_access(curr_quanta);
        }
        // This is the first time we are seeing this line
        else
        {
#ifdef SAMPLING
            // Find a victim from the sampled cache if we are sampling
            assert(addr_history[sampler_set].size() < SAMPLER_WAYS);
            if(addr_history[sampler_set].size() == SAMPLER_WAYS) 
                replace_addr_history_element(sampler_set);

            assert(addr_history[sampler_set].size() < SAMPLER_WAYS);
#endif
            //Initialize a new entry in the sampler
            addr_history[sampler_set][sampler_tag].init(curr_quanta);
            perset_optgen[set].add_access(curr_quanta);
        }
        cout << endl;

        // Get Hawkeye's prediction for this line
        Result result = demand_predictor->single_core_predictors[cpu]->get_prediction(ip, curr_histories[cpu], paddr);
        int new_prediction = result.prediction[result.current];
            
        // Update the sampler with the timestamp, PC and our prediction
        // For prefetches, the PC will represent the trigger PC
        addr_history[sampler_set][sampler_tag].update(perset_mytimer[set], ip, result.prediction[result.current]);
        addr_history[sampler_set][sampler_tag].lru = 0;
        addr_history[sampler_set][sampler_tag].context = curr_histories[cpu];
        addr_history[sampler_set][sampler_tag].detrained = false;
        addr_history[sampler_set][sampler_tag].prev_result = result;
        addr_history[sampler_set][sampler_tag].cpu = cpu;
       
        if(per_pc_stats.find(ip) == per_pc_stats.end())
            per_pc_stats[ip].init();

        if(new_prediction > 0) 
        {
            hit_predictions[cpu]++;
            per_pc_stats[ip].hit_predictions++;
        }
        else 
        {
            miss_predictions[cpu]++;
            per_pc_stats[ip].miss_predictions++;
        }


        //Increment the set timer
        perset_mytimer[set] = (perset_mytimer[set]+1) % TIMER_SIZE;
    }

    Result result = demand_predictor->single_core_predictors[cpu]->get_prediction(ip, curr_histories[cpu], paddr);
    int new_prediction = result.prediction[result.current];

    signatures[set][way] = ip;
    addresses[set][way] = paddr;   

    assert(curr_histories[cpu].size() <= HISTORY_LENGTH);
    curr_histories[cpu].push_back(ip);
    if(curr_histories[cpu].size() > HISTORY_LENGTH)
        curr_histories[cpu].erase(curr_histories[cpu].begin());
    assert(curr_histories[cpu].size() <= HISTORY_LENGTH);

    //Set RRIP values and age cache-friendly line
    if(new_prediction == 0)
        rrpv[set][way] = maxRRPV;
    else
    {
        rrpv[set][way] = 0;
        if(!hit)
        {
            bool saturated = false;
            for(uint32_t i=0; i<LLC_WAYS; i++)
                if (rrpv[set][i] == maxRRPV-1)
                    saturated = true;

            //Age all the cache-friendly lines
            for(uint32_t i=0; i<LLC_WAYS; i++)
            {
                if (!saturated && rrpv[set][i] < maxRRPV-1)
                    rrpv[set][i]++;
            }
        }
        //=============RRPV modifications================
        if(new_prediction == 1) // predictor is not confident about this
            rrpv[set][way] = middle_RRPV;
        else if(new_prediction == 2) // predictor is quite confident about this
            rrpv[set][way] = 0;
        else //shouldn't arrive here, only two possible RRPV values for cache-friendly lines
            assert(0);
        //=============RRPV modifications================
    }
}

// use this function to print out your own stats at the end of simulation
void CACHE::llc_replacement_final_stats()
{
    unsigned int hits = 0;
    unsigned int accesses = 0;
    //unsigned int traffic = 0;
    for(unsigned int i=0; i<LLC_SETS; i++)
    {
        accesses += perset_optgen[i].access;
        hits += perset_optgen[i].get_num_opt_hits();
     //   traffic += perset_optgen[i].get_traffic();

        if(perset_optgen[i].access != 0)
            cout << i << " " << perset_optgen[i].access << " " << perset_optgen[i].get_num_opt_hits() << endl;
    }

    std::cout << "OPTgen accesses: " << accesses << std::endl;
    std::cout << "OPTgen hits: " << hits << std::endl;
    std::cout << "OPTgen hit rate: " << 100*(double)hits/(double)accesses << std::endl;
    //std::cout << "Traffic: " << traffic << " " << 100*(double)traffic/(double)accesses << std::endl;

    for(int i = 0; i < NUM_CPUS; i++)
    {
        cout << "CPU: " << i << endl;
        cout << "predicted friendly lines by writebacks: " << evicted_by_wb[i] << endl;

        int num_interval = demand_predictor->single_core_predictors[i]->num_intervals;        
        double* past_threshold = demand_predictor->single_core_predictors[i]->past_thresholds;
    
        // cout << endl;
        // cout << "both hits: " << num_both_hits[i] << endl;
        // cout << "practical hits: " << num_practical_hits[i] << endl;
        // cout << "optimal hits: " << num_optimal_hits[i] << endl;
        // cout << "both hit / practical Ratio: " << 100 * (double)num_both_hits[i] / (double)num_practical_hits[i] << endl;
        // cout << "both hit / optimal Ratio: " << 100 * (double)num_both_hits[i] / (double)num_optimal_hits[i] << endl;
        // cout << endl;
        
        // cout << "detraining: " << num_detraining[i] << endl;
        // cout << "correct detraining: " << num_correct_detraining[i] << endl;
        // cout << "correct detraining Ratio: " << 100 * (double)num_correct_detraining[i] / (double)num_detraining[i] << endl;
        // cout << "wrong detraining: " << num_wrong_detraining[i] << endl;
        // cout << "wrong detraining Ratio: " << 100 * (double)num_wrong_detraining[i] / (double)num_detraining[i] << endl;
        // cout << endl;

        cout << "Hit Accuracy: " << 100*(double)hit_accurate[i] / (double)(hit_accurate[i] + hit_inaccurate[i]) << endl;
        cout << "Total Ground Truth Hits: " << (hit_accurate[i] + hit_inaccurate[i]) << endl; 
        cout << "Miss Accuracy: " << 100*(double)miss_accurate[i] / (double)(miss_accurate[i] + miss_inaccurate[i]) << endl;
        cout << "Total Ground Truth Misses: " << (miss_accurate[i] + miss_inaccurate[i]) << endl;

        assert(no_feedback_accurate[i] == 0);
        assert(miss_predictions[i] >= (miss_accurate[i] + hit_inaccurate[i]));
        no_feedback_accurate[i] = miss_predictions[i] - miss_accurate[i] - hit_inaccurate[i];
        cout << "No Feedback Accuracy: " << 100*(double)(no_feedback_accurate[i])/ (double)(no_feedback_accurate[i] + no_feedback_inaccurate[i]) << endl;
        cout << "Num No Feedback: " << (no_feedback_accurate[i] + no_feedback_inaccurate[i]) << endl;

        
        cout << "Overall Accuracy: " << 100*(double)(hit_accurate[i]+miss_accurate[i]) / (double)(hit_accurate[i] + hit_inaccurate[i] + miss_accurate[i] + miss_inaccurate[i]) << endl;
        cout << "Overall Accuracy including no feedback: " << 100*(double)(hit_accurate[i]+miss_accurate[i]+no_feedback_accurate[i]) / (double)(hit_accurate[i] + hit_inaccurate[i] + miss_accurate[i] + miss_inaccurate[i] + no_feedback_accurate[i] + no_feedback_inaccurate[i]) << endl;

        cout << "threshold history: " << endl;
        for(int j = 0; j < num_interval; j++)
            cout << past_threshold[j] << " ";
        cout << endl << endl;

        // now we want to see the accuracy of predictions of different confidence
        // it's distribution, not cdf
        // we divide the range below threshold into 20 intervals, with 1/20 * threshold as step
        // divide the range above threshold into 30 intervals, this is not that important
        cout << "accuracy distribution over confidence: " << endl;
        double* confidence_up = demand_predictor->single_core_predictors[i]->confidence_histogram_up;
        double* confidence_down = demand_predictor->single_core_predictors[i]->confidence_histogram_down;
        for(int j = 0; j < 51; j++)
        {
            cout << confidence_up[j] / confidence_down[j] << " = " << confidence_up[j] << " / " << confidence_down[j] << endl;
            if(j == 19)
                cout << endl;
        }
    }

    cout << "number of training: " << num_train << endl;
    cout << endl << endl;
    cout << endl << endl;
    cout << endl << endl;
    cout << endl << endl;
    for(map<uint64_t, PCSTATS>::iterator it=per_pc_stats.begin(); it != per_pc_stats.end(); it++)
    {
        //TODO: Change CPU
        if( (double)((it->second).accesses()) < 0.02*(double)(hit_accurate[0] + miss_accurate[0] + hit_inaccurate[0] + miss_inaccurate[0] + no_feedback_accurate[0] + no_feedback_inaccurate[0]))
            continue;

        cout << it->first << " ";
        (it->second).print();
        demand_predictor->single_core_predictors[0]->print(it->first);
        cout << endl;
    }
    return;
}
